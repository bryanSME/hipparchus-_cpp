/*\r\n\r\n * Licensed to the Hipparchus project under one or more\r\n\r\n * contributor license agreements.  See the NOTICE file distributed with\r\n\r\n * this work for additional information regarding copyright ownership.\r\n\r\n * The Hipparchus project licenses this file to You under the Apache License, Version 2.0\r\n\r\n * (the "License"); you may not use this file except in compliance with\r\n\r\n * the License.  You may obtain a copy of the License at\r\n\r\n *\r\n\r\n *      http://www.apache.org/licenses/LICENSE-2.0\r\n\r\n *\r\n\r\n * Unless required by applicable law or agreed to in writing, software\r\n\r\n * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n\r\n * See the License for the specific language governing permissions and\r\n\r\n * limitations under the License.\r\n\r\n */\r\n\r\n//package org.hipparchus.analysis.differentiation;\r\n\r\n#include <cmath>\r\n\r\n#include "../../CalculusFieldElement.h"\r\n\r\n#include "Derivative.h"\r\n\r\n#include <vector>\r\n\r\n#include <algorithm>\r\n\r\n#include <numbers>\r\n\r\n#include "../../util/MathArrays.h"\r\n\r\n#include "../../util/SinCos.h"\r\n\r\n//import java.io.Serializable;\r\n\r\n//import java.util.Arrays;\r\n\r\n\r\n\r\n//import org.hipparchus.Calculus_Field_Element;\r\n\r\n//import org.hipparchus.exception.Localized_Core_Formats;\r\n\r\n//import org.hipparchus.exception.;\r\n\r\n//import org.hipparchus.util.FastMath;\r\n\r\n//import org.hipparchus.util.Field_Sin_Cos;\r\n\r\n//import org.hipparchus.util.Field_Sinh_Cosh;\r\n\r\n//import org.hipparchus.util.Math_Arrays;\r\n\r\n//import org.hipparchus.util.Math_Utils;\r\n\r\n//import org.hipparchus.util.Sin_Cos;\r\n\r\n//import org.hipparchus.util.Sinh_Cosh;\r\n\r\n\r\n\r\n/** Class representing both the value and the differentials of a function.\r\n\r\n * <p>This class is a stripped-down version of {@link Derivative_Structure}\r\n\r\n * with {@link Derivative_Structure#get_order() derivation order} limited to one.\r\n\r\n * It should have less overhead than {@link Derivative_Structure} in its domain.</p>\r\n\r\n * <p>This class is an implementation of Rall's numbers. Rall's numbers are an\r\n\r\n * extension to the real numbers used throughout mathematical expressions; they hold\r\n\r\n * the derivative together with the value of a function.</p>\r\n\r\n * <p>{@link Gradient} instances can be used directly thanks to\r\n\r\n * the arithmetic operators to the mathematical functions provided as\r\n\r\n * methods by this class (+, -, *, /, %, sin, cos ...).</p>\r\n\r\n * <p>Implementing complex expressions by hand using these classes is\r\n\r\n * a tedious and error-prone task but has the advantage of having no limitation\r\n\r\n * on the derivation order despite not requiring users to compute the derivatives by\r\n\r\n * themselves.</p>\r\n\r\n * <p>Instances of this class are guaranteed to be immutable.</p>\r\n\r\n * @see Derivative_Structure\r\n\r\n * @see Univariate_Derivative_1\r\n\r\n * @see Univariate_Derivative_2\r\n\r\n * @see Field_Derivative_Structure\r\n\r\n * @see Field_Univariate_Derivative_1\r\n\r\n * @see Field_Univariate_Derivative_2\r\n\r\n * @see Field_Gradient\r\n\r\n * @since 1.7\r\n\r\n */\r\n\r\nclass Gradient : Derivative<Gradient>, Calculus_Field_Element<Gradient>\r\n\r\n{\r\n\r\nprivate:\r\n\r\n\r\n\r\n    /** Value of the function. */\r\n\r\n    const double my_value;\r\n\r\n\r\n\r\n    /** Gradient of the function. */\r\n\r\n    const std::vector<double> my_grad;\r\n\r\n\r\n\r\n    /** Build an instance with values and unitialized derivatives array.\r\n\r\n     * @param value value of the function\r\n\r\n     * @param free_parameters number of free parameters\r\n\r\n     */\r\n\r\n    Gradient(const double& value, int free_parameters) : my_value{ value }, my_grad{ std::vector<double>(free_parameters) } {};\r\n\r\n\r\n\r\npublic:\r\n\r\n    /** Build an instance with values and derivative.\r\n\r\n     * @param value value of the function\r\n\r\n     * @param gradient gradient of the function\r\n\r\n     */\r\n\r\n    Gradient(const double& value, const std::vector<double>& gradient) \r\n\r\n    {\r\n\r\n        *(my_value, gradient.size());\r\n\r\n        System.arraycopy(gradient, 0, my_grad, 0, my_grad.size());\r\n\r\n    }\r\n\r\n\r\n\r\n    /** Build an instance from a {@link Derivative_Structure}.\r\n\r\n     * @param ds derivative structure\r\n\r\n     * @exception  if {@code ds} order\r\n\r\n     * is not 1\r\n\r\n     */\r\n\r\n    Gradient(const Derivative_Structure& ds)  \r\n\r\n    {\r\n\r\n        this(ds.get_value(), ds.get_free_parameters());\r\n\r\n        Math_Utils::check_dimension(ds.get_order(), 1);\r\n\r\n        System.arraycopy(ds.get_all_derivatives(), 1, my_grad, 0, my_grad.size());\r\n\r\n    }\r\n\r\n\r\n\r\n    /** Build an instance corresponding to a constant value.\r\n\r\n     * @param free_parameters number of free parameters (i.e. dimension of the gradient)\r\n\r\n     * @param value constant value of the function\r\n\r\n     * @return a {@code Gradient} with a constant value and all derivatives set to 0.0\r\n\r\n     */\r\n\r\n    static Gradient constant(const int& free_parameters, const double& value) \r\n\r\n    {\r\n\r\n        return Gradient(value, free_parameters);\r\n\r\n    }\r\n\r\n\r\n\r\n    /** Build a {@code Gradient} representing a variable.\r\n\r\n     * <p>Instances built using this method are considered\r\n\r\n     * to be the free variables with respect to which differentials\r\n\r\n     * are computed. As such, their differential with respect to\r\n\r\n     * themselves is +1.</p>\r\n\r\n     * @param free_parameters number of free parameters (i.e. dimension of the gradient)\r\n\r\n     * @param index index of the variable (from 0 to {@link #get_free_parameters() get_free_parameters()} - 1)\r\n\r\n     * @param value value of the variable\r\n\r\n     * @return a {@code Gradient} with a constant value and all derivatives set to 0.0 except the\r\n\r\n     * one at {@code index} which will be set to 1.0\r\n\r\n     */\r\n\r\n    static Gradient variable(const int& free_parameters, const int& index, const double& value) \r\n\r\n    {\r\n\r\n        const Gradient g = Gradient(value, free_parameters);\r\n\r\n        g.get_gradient()[index] = 1.0;\r\n\r\n        return g;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient new_instance(const double& c) \r\n\r\n    {\r\n\r\n        return Gradient(c, std::vector<double>(my_grad.size()));\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    double get_real() const\r\n\r\n    {\r\n\r\n        return get_value();\r\n\r\n    }\r\n\r\n\r\n\r\n    /** Get the value part of the function.\r\n\r\n     * @return value part of the value of the function\r\n\r\n     */\r\n\r\n    //override\r\n\r\n    double get_value() const\r\n\r\n    {\r\n\r\n        return my_value;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** Get the gradient part of the function.\r\n\r\n     * @return gradient part of the value of the function\r\n\r\n     * @see #get_partial_derivativestatic_cast<int>(\r\n\r\n     */\r\n\r\n    std::vector<double> get_gradient() const\r\n\r\n    {\r\n\r\n        return my_grad;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    int get_free_parameters() const\r\n\r\n    {\r\n\r\n        return my_grad.size();\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    int get_order() const\r\n\r\n    {\r\n\r\n        return 1;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    double get_partial_derivative(const std::vector<int>& orders)\r\n\r\n    {\r\n\r\n        // check the number of components\r\n\r\n        if (orders.size() != my_grad.size())\r\n\r\n        {\r\n\r\n            throw (Localized_Core_Formats.DIMENSIONS_MISMATCH, orders.size(), my_grad.size());\r\n\r\n        }\r\n\r\n\r\n\r\n        // check that either all derivation orders are set to 0, // or that only one is set to 1 and all other ones are set to 0\r\n\r\n        int selected{ -1 };\r\n\r\n        for (int i{}; i < orders.size(); ++i) \r\n\r\n        {\r\n\r\n            if (orders[i] != 0) \r\n\r\n            {\r\n\r\n                if (selected >= 0 || orders[i] != 1) \r\n\r\n                {\r\n\r\n                     throw (Localized_Core_Formats.DERIVATION_ORDER_NOT_ALLOWED, orders[i]);\r\n\r\n                }\r\n\r\n                // found the component set to derivation order 1\r\n\r\n                selected = i;\r\n\r\n            }\r\n\r\n        }\r\n\r\n\r\n\r\n        return selected < 0\r\n\r\n            ? my_value\r\n\r\n            : my_grad[selected];\r\n\r\n\r\n\r\n    }\r\n\r\n\r\n\r\n    /** Get the partial derivative with respect to one parameter.\r\n\r\n     * @param n index of the parameter (counting from 0)\r\n\r\n     * @return partial derivative with respect to the n<sup>th</sup> parameter\r\n\r\n     * @exception  if n is either negative or larger\r\n\r\n     * or equal to {@link #get_free_parameters()}\r\n\r\n     */\r\n\r\n    double get_partial_derivative(const int& n)  \r\n\r\n    {\r\n\r\n        if (n < 0 || n >= my_grad.size())\r\n\r\n        {\r\n\r\n            throw (Localized_Core_Formats.OUT_OF_RANGE_SIMPLE, n, 0, my_grad.size() - 1);\r\n\r\n        }\r\n\r\n        return my_grad[n];\r\n\r\n    }\r\n\r\n\r\n\r\n    /** Convert the instance to a {@link Derivative_Structure}.\r\n\r\n     * @return derivative structure with same value and derivative as the instance\r\n\r\n     */\r\n\r\n    Derivative_Structure to_derivative_structure() \r\n\r\n    {\r\n\r\n        auto derivatives = std::vector<double>(1 + my_grad.size());\r\n\r\n        derivatives[0] = my_value;\r\n\r\n        System.arraycopy(my_grad, 0, derivatives, 1, my_grad.size());\r\n\r\n        return get_field().get_conversion_factory().build(derivatives);\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient add(const double& a) \r\n\r\n    {\r\n\r\n        return Gradient(my_value + a, my_grad);\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient add(const Gradient& a) \r\n\r\n    {\r\n\r\n        auto result = new_instance(my_value + a.get_value());\r\n\r\n        for (int i{}; i < my_grad.size(); ++i)\r\n\r\n        {\r\n\r\n            result.get_gradient()[i] = my_grad[i] + a.get_gradient()[i];\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient subtract(const double& a) const\r\n\r\n    {\r\n\r\n        return Gradient(my_value - a, my_grad);\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient subtract(const Gradient& a) \r\n\r\n    {\r\n\r\n        auto result = new_instance(my_value - a.get_value());\r\n\r\n        for (int i{}; i < my_grad.size(); ++i)\r\n\r\n        {\r\n\r\n            result.get_gradient()[i] = my_grad[i] - a.get_gradient()[i];\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient multiply(const int& n) \r\n\r\n    {\r\n\r\n        auto result = new_instance(my_value * n);\r\n\r\n        for (int i{}; i < my_grad.size(); ++i) \r\n\r\n        {\r\n\r\n            result.get_gradient()[i] = my_grad[i] * n;\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient multiply(const double& a) \r\n\r\n    {\r\n\r\n        auto result = new_instance(my_value * a);\r\n\r\n        for (int i{}; i < my_grad.size(); ++i) \r\n\r\n        {\r\n\r\n            result.get_gradient()[i] = my_grad[i] * a;\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient multiply(const Gradient& a) \r\n\r\n    {\r\n\r\n        auto result = new_instance(my_value * a.get_value());\r\n\r\n        for (int i{}; i < my_grad.size(); ++i) \r\n\r\n        {\r\n\r\n            result.get_gradient()[i] = my_grad[i] * a.get_value() + my_value * a.get_gradient()[i];\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient divide(const double& a) \r\n\r\n    {\r\n\r\n        auto result = new_instance(my_value / a);\r\n\r\n        for (int i{}; i < my_grad.size(); ++i) \r\n\r\n        {\r\n\r\n            result.get_gradient()[i] = my_grad[i] / a;\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient divide(const Gradient& a) \r\n\r\n    {\r\n\r\n        const double inv1 = 1.0 / a.get_value();\r\n\r\n        const double inv2 = inv1 * inv1;\r\n\r\n        auto result = new_instance(my_value * inv1);\r\n\r\n        for (int i{}; i < my_grad.size(); ++i) \r\n\r\n        {\r\n\r\n            result.get_gradient()[i] = (my_grad[i] * a.get_value() - my_value * a.get_gradient()[i]) * inv2;\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient remainder(const double& a) \r\n\r\n    {\r\n\r\n        return Gradient(std::remainder(my_value, a), my_grad);\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient remainder(const Gradient& a) \r\n\r\n    {\r\n\r\n\r\n\r\n        // compute k such that lhs % rhs = lhs - k rhs\r\n\r\n        const double rem = std::remainder(my_value, a.get_value());\r\n\r\n        const double k   = FastMath.rint((my_value - rem) / a.get_value());\r\n\r\n\r\n\r\n        auto result = new_instance(rem);\r\n\r\n        for (int i{}; i < my_grad.size(); ++i) \r\n\r\n        {\r\n\r\n            result.get_gradient()[i] = my_grad[i] - k * a.get_gradient()[i];\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient negate() \r\n\r\n    {\r\n\r\n        auto result = new_instance(-value);\r\n\r\n        for (int i{}; i < my_grad.size(); ++i) \r\n\r\n        {\r\n\r\n            result.get_gradient()[i] = -grad[i];\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient abs() \r\n\r\n    {\r\n\r\n        if (Double.double_to_long_bits(my_value) < 0) \r\n\r\n        {\r\n\r\n            // we use the bits representation to also handle -0.0\r\n\r\n            return negate();\r\n\r\n        }\r\n\r\nelse \r\n\r\n        {\r\n\r\n            return this;\r\n\r\n        }\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient ceil() \r\n\r\n    {\r\n\r\n        return new_instance(FastMath.ceil(my_value));\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient floor() \r\n\r\n    {\r\n\r\n        return new_instance(std::floor(my_value));\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient rint() \r\n\r\n    {\r\n\r\n        return new_instance(FastMath.rint(my_value));\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient sign() \r\n\r\n    {\r\n\r\n        return new_instance(FastMath.signum(my_value));\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient copy_sign(const Gradient& sign) \r\n\r\n    {\r\n\r\n        long m = Double.double_to_long_bits(my_value);\r\n\r\n        long s = Double.double_to_long_bits(sign.get_value());\r\n\r\n        if ((m >= 0 && s >= 0) || (m < 0 && s < 0)) { // Sign is currently OK\r\n\r\n            return this;\r\n\r\n        }\r\n\r\n        return negate(); // flip sign\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient copy_sign(const double sign) \r\n\r\n    {\r\n\r\n        long m = Double.double_to_long_bits(my_value);\r\n\r\n        long s = Double.double_to_long_bits(sign);\r\n\r\n        if ((m >= 0 && s >= 0) || (m < 0 && s < 0)) { // Sign is currently OK\r\n\r\n            return this;\r\n\r\n        }\r\n\r\n        return negate(); // flip sign\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    int get_exponent() \r\n\r\n    {\r\n\r\n        return FastMath.get_exponent(my_value);\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient scalb(const int& n) \r\n\r\n    {\r\n\r\n        const auto result = new_instance(std::scalbn(my_value, n));\r\n\r\n        for (int i{}; i < my_grad.size(); ++i) \r\n\r\n        {\r\n\r\n            result.get_gradient()[i] = std::scalbn(my_grad[i], n);\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc}\r\n\r\n     * <p>\r\n\r\n     * The {@code ulp} function is a step function, hence all its derivatives are 0.\r\n\r\n     * </p>\r\n\r\n     * @since 2.0\r\n\r\n     */\r\n\r\n    //override\r\n\r\n    Gradient ulp() \r\n\r\n    {\r\n\r\n        return new_instance(std::ulp(my_value));\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient hypot(const Gradient& y) \r\n\r\n    {\r\n\r\n\r\n\r\n        if (std::isinf(my_value) || std::isinf(y.get_value())) \r\n\r\n        {\r\n\r\n            return new_instance(INFINITY);\r\n\r\n        }\r\n\r\n        if (std::isnan(my_value) || std::isnan(y.get_value())) \r\n\r\n        {\r\n\r\n            return new_instance(NAN);\r\n\r\n        }\r\n\r\n\r\n\r\n\r\n\r\n        const int exp_x = get_exponent();\r\n\r\n        const int exp_y = y.get_exponent();\r\n\r\n        if (exp_x > exp_y + 27) \r\n\r\n        {\r\n\r\n            // y is neglectible with respect to x\r\n\r\n            return abs();\r\n\r\n        }\r\n\r\n        if (exp_y > exp_x + 27) \r\n\r\n        {\r\n\r\n            // x is neglectible with respect to y\r\n\r\n            return y.abs();\r\n\r\n        }\r\n\r\n\r\n\r\n\r\n\r\n        // find an intermediate scale to avoid both overflow and underflow\r\n\r\n        const int middle_exp = (exp_x + exp_y) / 2;\r\n\r\n\r\n\r\n        // scale parameters without losing precision\r\n\r\n        const auto scaled_x = scalb(-middle_exp);\r\n\r\n        const auto scaled_y = y.scalb(-middle_exp);\r\n\r\n\r\n\r\n        // compute scaled hypotenuse\r\n\r\n        const Gradient scaled_h =\r\n\r\n                scaled_x.multiply(scaled_x).add(scaled_y.multiply(scaled_y)).sqrt();\r\n\r\n\r\n\r\n        // remove scaling\r\n\r\n        return scaled_h.scalb(middle_exp);\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient reciprocal() \r\n\r\n    {\r\n\r\n        const double inv1 = 1.0 / my_value;\r\n\r\n        const double inv2 = inv1 * inv1;\r\n\r\n        auto result = new_instance(inv1);\r\n\r\n        for (int i{}; i < my_grad.size(); ++i) \r\n\r\n        {\r\n\r\n            result.get_gradient()[i] = -my_grad[i] * inv2;\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient compose(const std::vector<double>& f) \r\n\r\n    {\r\n\r\n       Math_Utils::check_dimension(f.size(), get_order() + 1);\r\n\r\n       auto result = new_instance(f[0]);\r\n\r\n        for (int i{}; i < my_grad.size(); ++i) \r\n\r\n        {\r\n\r\n            result.get_gradient()[i] = f[1] * my_grad[i];\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient sqrt() \r\n\r\n    {\r\n\r\n        const double s = std::sqrt(my_value);\r\n\r\n        return compose(s, 1 / (2 * s));\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient cbrt() \r\n\r\n    {\r\n\r\n        const auto c = std::cbrt(my_value);\r\n\r\n        return compose(c, 1 / (3 * c * c));\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient root_n(const int& n) \r\n\r\n    {\r\n\r\n        if (n == 2) \r\n\r\n        {\r\n\r\n            return sqrt();\r\n\r\n        }\r\n\r\n        if (n == 3) \r\n\r\n        {\r\n\r\n            return cbrt();\r\n\r\n        }\r\n\r\n\r\n\r\n        const double r = std::pow(my_value, 1.0 / n);\r\n\r\n        return compose(r, 1 / (n * std::pow(r, n - 1)));\r\n\r\n        \r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient_Field get_field() \r\n\r\n    {\r\n\r\n        return Gradient_Field.get_field(get_free_parameters());\r\n\r\n    }\r\n\r\n\r\n\r\n    /** Compute a<sup>x</sup> where a is a double and x a {@link Gradient}\r\n\r\n     * @param a number to exponentiate\r\n\r\n     * @param x power to apply\r\n\r\n     * @return a<sup>x</sup>\r\n\r\n     */\r\n\r\n    static Gradient pow(const double& a, const Gradient& x) \r\n\r\n    {\r\n\r\n        if (a == 0) \r\n\r\n        {\r\n\r\n            return x.get_field().get_zero();\r\n\r\n        }\r\n\r\n\r\n\r\n        const double& a_x = std::pow(a, x.get_value());\r\n\r\n        const double& a_xln_a = a_x * std::log(a);\r\n\r\n        auto result = x.new_instance(a_x);\r\n\r\n        for (int i{}; i < x.get_gradient().size(); ++i)\r\n\r\n        {\r\n\r\n            result.get_gradient()[i] =  a_xln_a * x.get_gradient()[i];\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n        \r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient pow(const double& p) \r\n\r\n    {\r\n\r\n        if (p == 0) \r\n\r\n        {\r\n\r\n            return get_field().get_one();\r\n\r\n        }\r\n\r\n\r\n\r\n        const auto value_pm1 = std::pow(my_value, p - 1);\r\n\r\n        return compose(value_pm1 * my_value, p * value_pm1);\r\n\r\n        \r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient pow(const int& n) \r\n\r\n    {\r\n\r\n        if (n == 0) \r\n\r\n        {\r\n\r\n            return get_field().get_one();\r\n\r\n        }\r\n\r\n\r\n\r\n        const double value_nm1 = std::pow(my_value, n - 1);\r\n\r\n        return compose(value_nm1 * my_value, n * value_nm1);\r\n\r\n        \r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient pow(const Gradient& e) \r\n\r\n    {\r\n\r\n        return log().multiply(e).exp();\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient exp() \r\n\r\n    {\r\n\r\n        const double exp = std::exp(my_value);\r\n\r\n        return compose(exp, exp);\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient expm1() \r\n\r\n    {\r\n\r\n        const double exp   = std::exp(my_value);\r\n\r\n        const double exp_m1 = std::expm1(my_value);\r\n\r\n        return compose(exp_m1, exp);\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient log() \r\n\r\n    {\r\n\r\n        return compose(std::log(my_value), 1 / my_value);\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient log1p() \r\n\r\n    {\r\n\r\n        return compose(std::log1p(my_value), 1 / (1 + my_value));\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient log10() \r\n\r\n    {\r\n\r\n        return compose(std::log10(my_value), 1 / (my_value * std::log(10.0)));\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient cos() \r\n\r\n    {\r\n\r\n        const Sin_Cos sin_cos = Sin_Cos(my_value);\r\n\r\n        return compose(sin_cos.cos(), -sin_cos.sin());\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient sin() \r\n\r\n    {\r\n\r\n        const Sin_Cos sin_cos = Sin_Cos(my_value);\r\n\r\n        return compose(sin_cos.sin(), sin_cos.cos());\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Field_Sin_Cos<Gradient> sin_cos() \r\n\r\n    {\r\n\r\n        const Sin_Cos sin_cos = Sin_Cos(my_value);\r\n\r\n        auto sin = new_instance(sin_cos.sin());\r\n\r\n        auto cos = new_instance(sin_cos.cos());\r\n\r\n        for (int i{}; i < my_grad.size(); ++i) \r\n\r\n        {\r\n\r\n            sin.get_gradient()[i] =  +my_grad[i] * sin_cos.cos();\r\n\r\n            cos.get_gradient()[i] =  -my_grad[i] * sin_cos.sin();\r\n\r\n        }\r\n\r\n        return Field_Sin_Cos<>(sin, cos);\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient tan() \r\n\r\n    {\r\n\r\n        const double tan = std::tan(my_value);\r\n\r\n        return compose(tan, 1 + tan * tan);\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient acos() \r\n\r\n    {\r\n\r\n        return compose(std::acos(my_value), -1 / std::sqrt(1 - my_value * my_value));\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient asin() \r\n\r\n    {\r\n\r\n        return compose(std::asin(my_value), 1 / std::sqrt(1 - my_value * my_value));\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient atan() \r\n\r\n    {\r\n\r\n        return compose(std::atan(my_value), 1 / (1 + my_value * my_value));\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient atan2(const Gradient& x) \r\n\r\n    {\r\n\r\n        const double inv = 1.0 / (my_value * my_value + x.get_value() * x.get_value());\r\n\r\n        auto result = new_instance(std::atan2(my_value, x.get_value()));\r\n\r\n        for (int i{}; i < my_grad.size(); ++i) \r\n\r\n        {\r\n\r\n            result.get_gradient()[i] = (x.get_value() * my_grad[i] - x.get_gradient()[i] * my_value) * inv;\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient cosh() \r\n\r\n    {\r\n\r\n        return compose(std::cosh(my_value), std::sinh(my_value));\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient sinh() \r\n\r\n    {\r\n\r\n        return compose(std::sinh(my_value), std::cosh(my_value));\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Field_Sinh_Cosh<Gradient> sinh_cosh() \r\n\r\n    {\r\n\r\n        const Sinh_Cosh sinh_cosh = std::sinh_cosh(my_value);\r\n\r\n        const Gradient sinh = new_instance(sinh_cosh.sinh());\r\n\r\n        const Gradient cosh = new_instance(sinh_cosh.cosh());\r\n\r\n        for (int i{}; i < my_grad.size(); ++i) \r\n\r\n        {\r\n\r\n            sinh.get_gradient()[i] = my_grad[i] * sinh_cosh.cosh();\r\n\r\n            cosh.get_gradient()[i] = my_grad[i] * sinh_cosh.sinh();\r\n\r\n        }\r\n\r\n        return Field_Sinh_Cosh<>(sinh, cosh);\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient tanh() \r\n\r\n    {\r\n\r\n        const double tanh = std::tanh(my_value);\r\n\r\n        return compose(tanh, 1 - tanh * tanh);\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient acosh() \r\n\r\n    {\r\n\r\n        return compose(std::acosh(my_value), 1 / std::sqrt(my_value * my_value - 1));\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient asinh() \r\n\r\n    {\r\n\r\n        return compose(std::asinh(my_value), 1 / std::sqrt(my_value * my_value + 1));\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient atanh() \r\n\r\n    {\r\n\r\n        return compose(std::atanh(my_value), 1 / (1 - my_value * my_value));\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient to_degrees() \r\n\r\n    {\r\n\r\n        auto result = new_instance(FastMath.to_degrees(my_value));\r\n\r\n        for (int i{}; i < my_grad.size(); ++i) \r\n\r\n        {\r\n\r\n            result.get_gradient()[i] = FastMath.to_degrees(my_grad[i]);\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient to_radians() \r\n\r\n    {\r\n\r\n        auto result = new_instance(FastMath.to_radians(my_value));\r\n\r\n        for (int i{}; i < my_grad.size(); ++i) \r\n\r\n        {\r\n\r\n            result.get_gradient()[i] = FastMath.to_radians(my_grad[i]);\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** Evaluate Taylor expansion a derivative structure.\r\n\r\n     * @param delta parameters offsets (&Delta;x, &Delta;y, ...)\r\n\r\n     * @return value of the Taylor expansion at x + &Delta;x, y + &Delta;y, ...\r\n\r\n     */\r\n\r\n    double taylor(const std::vector<double>& delta) \r\n\r\n    {\r\n\r\n        auto result = my_value;\r\n\r\n        for (int i{}; i < my_grad.size(); ++i) \r\n\r\n        {\r\n\r\n            result += delta[i] * my_grad[i];\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient linear_combination(const std::vector<Gradient>& a, const std::vector<Gradient>& b) \r\n\r\n    {\r\n\r\n\r\n\r\n        // extract values and first derivatives\r\n\r\n        const auto n  = a.size();\r\n\r\n        auto a0 = std::vector<double>(n);\r\n\r\n        auto b0 = std::vector<double>(n);\r\n\r\n        auto a1 = std::vector<double>(2 * n);\r\n\r\n        auto b1 = std::vector<double>(2 * n);\r\n\r\n        for (int i{}; i < n; ++i) \r\n\r\n        {\r\n\r\n            const auto ai = a[i];\r\n\r\n            const auto bi = b[i];\r\n\r\n            a0[i]         = ai.get_value();\r\n\r\n            b0[i]         = bi.get_value();\r\n\r\n            a1[2 * i]     = ai.get_value();\r\n\r\n            b1[2 * i + 1] = bi.get_value();\r\n\r\n        }\r\n\r\n\r\n\r\n        auto result = new_instance(Math_Arrays::linear_combination(a0, b0));\r\n\r\n        for (int k{}; k < my_grad.size(); ++k) \r\n\r\n        {\r\n\r\n            for (int i{}; i < n; ++i) \r\n\r\n            {\r\n\r\n                a1[2 * i + 1] = a[i].get_gradient()[k];\r\n\r\n                b1[2 * i]     = b[i].get_gradient()[k];\r\n\r\n            }\r\n\r\n            result.get_gradient()[k] = Math_Arrays::linear_combination(a1, b1);\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient linear_combination(const std::vector<double> a, const std::vector<Gradient>& b) \r\n\r\n    {\r\n\r\n\r\n\r\n        // extract values and first derivatives\r\n\r\n        const auto n  = b.size();\r\n\r\n        auto b0 = std::vector<double>(n);\r\n\r\n        auto b1 = std::vector<double>(n);\r\n\r\n        for (int i{}; i < n; ++i) \r\n\r\n        {\r\n\r\n            b0[i] = b[i].get_value();\r\n\r\n        }\r\n\r\n\r\n\r\n        auto result = new_instance(Math_Arrays::linear_combination(a, b0));\r\n\r\n        for (int k{}; k < my_grad.size(); ++k) \r\n\r\n        {\r\n\r\n            for (int i{}; i < n; ++i) \r\n\r\n            {\r\n\r\n                b1[i] = b[i].get_gradient()[k];\r\n\r\n            }\r\n\r\n            result.get_gradient()[k] = Math_Arrays::linear_combination(a, b1);\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient linear_combination(const Gradient& a1, const Gradient& b1, const Gradient& a2, const Gradient& b2) \r\n\r\n    {\r\n\r\n        auto result = new_instance(Math_Arrays::linear_combination(a1.get_value(), b1.get_value(), a2.get_value(), b2.get_value()));\r\n\r\n        for (int i{}; i < b1.get_gradient().size(); ++i)\r\n\r\n        {\r\n\r\n            result.get_gradient()[i] = Math_Arrays::linear_combination(a1.get_value(), b1.get_gradient()[i], a1.get_gradient()[i], b1.get_value(), a2.get_value(), b2.get_gradient()[i], a2.get_gradient()[i], b2.get_value());\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient linear_combination(const double& a1, const Gradient b1, const double& a2, const Gradient b2) \r\n\r\n    {\r\n\r\n        auto result = new_instance(Math_Arrays::linear_combination(a1, b1.get_value(), a2, b2.get_value()));\r\n\r\n        for (int i{}; i < b1.get_gradient().size(); ++i)\r\n\r\n        {\r\n\r\n            result.get_gradient()[i] = Math_Arrays::linear_combination(a1, b1.get_gradient()[i], a2, b2.get_gradient()[i]);\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient linear_combination(const Gradient& a1, const Gradient b1, const Gradient a2, const Gradient b2, const Gradient a3, const Gradient b3) \r\n\r\n    {\r\n\r\n        const std::vector<double> a = \r\n\r\n        {\r\n\r\n            a1.get_value(), 0, a2.get_value(), 0, a3.get_value(), 0\r\n\r\n        };\r\n\r\n        const std::vector<double> b = \r\n\r\n        {\r\n\r\n            0, b1.get_value(), 0, b2.get_value(), 0, b3.get_value()\r\n\r\n        };\r\n\r\n        auto result = new_instance(Math_Arrays::linear_combination(a1.get_value(), b1.get_value(), a2.get_value(), b2.get_value(), a3.get_value(), b3.get_value()));\r\n\r\n        for (int i{}; i < b1.get_gradient().size(); ++i)\r\n\r\n        {\r\n\r\n            a[1] = a1.get_gradient()[i];\r\n\r\n            a[3] = a2.get_gradient()[i];\r\n\r\n            a[5] = a3.get_gradient()[i];\r\n\r\n            b[0] = b1.get_gradient()[i];\r\n\r\n            b[2] = b2.get_gradient()[i];\r\n\r\n            b[4] = b3.get_gradient()[i];\r\n\r\n            result.get_gradient()[i] = Math_Arrays::linear_combination(a, b);\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient linear_combination(const double& a1, const Gradient b1, const double& a2, const Gradient b2, const double& a3, const Gradient b3) \r\n\r\n    {\r\n\r\n        auto result = new_instance(Math_Arrays::linear_combination(a1, b1.get_value(), a2, b2.get_value(), a3, b3.get_value()));\r\n\r\n        for (int i{}; i < b1.get_gradient().size(); ++i) \r\n\r\n        {\r\n\r\n            result.get_gradient()[i] = Math_Arrays::linear_combination(a1, b1.get_gradient()[i], a2, b2.get_gradient()[i], a3, b3.get_gradient()[i]);\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient linear_combination(const Gradient& a1, const Gradient b1, const Gradient a2, const Gradient b2, const Gradient a3, const Gradient b3, const Gradient a4, const Gradient b4) \r\n\r\n    {\r\n\r\n        std::vector<double> a = \r\n\r\n        {\r\n\r\n            a1.get_value(), 0, a2.get_value(), 0, a3.get_value(), 0, a4.get_value(), 0\r\n\r\n        };\r\n\r\n        std::vector<double> b = \r\n\r\n        {\r\n\r\n            0, b1.get_value(), 0, b2.get_value(), 0, b3.get_value(), 0, b4.get_value()\r\n\r\n        };\r\n\r\n        auto result = new_instance(Math_Arrays::linear_combination(a1.get_value(), b1.get_value(), a2.get_value(), b2.get_value(), a3.get_value(), b3.get_value(), a4.get_value(), b4.get_value()));\r\n\r\n        for (int i{}; i < b1.get_gradient().size(); ++i) \r\n\r\n        {\r\n\r\n            a[1] = a1.get_gradient()[i];\r\n\r\n            a[3] = a2.get_gradient()[i];\r\n\r\n            a[5] = a3.get_gradient()[i];\r\n\r\n            a[7] = a4.get_gradient()[i];\r\n\r\n            b[0] = b1.get_gradient()[i];\r\n\r\n            b[2] = b2.get_gradient()[i];\r\n\r\n            b[4] = b3.get_gradient()[i];\r\n\r\n            b[6] = b4.get_gradient()[i];\r\n\r\n            result.get_gradient()[i] = Math_Arrays::linear_combination(a, b);\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient linear_combination(const double& a1, const Gradient b1, const double& a2, const Gradient b2, const double& a3, const Gradient b3, const double& a4, const Gradient b4) \r\n\r\n    {\r\n\r\n        auto result = new_instance(Math_Arrays::linear_combination(a1, b1.get_value(), a2, b2.get_value(), a3, b3.get_value(), a4, b4.get_value()));\r\n\r\n        for (int i{}; i < b1.get_gradient().size(); ++i) \r\n\r\n        {\r\n\r\n            result.get_gradient()[i] = Math_Arrays::linear_combination(a1, b1.get_gradient()[i], a2, b2.get_gradient()[i], a3, b3.get_gradient()[i], a4, b4.get_gradient()[i]);\r\n\r\n        }\r\n\r\n        return result;\r\n\r\n    }\r\n\r\n\r\n\r\n    /** {@inherit_doc} */\r\n\r\n    //override\r\n\r\n    Gradient get_pi() \r\n\r\n    {\r\n\r\n        return Gradient(std::numbers::pi, get_free_parameters());\r\n\r\n    }\r\n\r\n\r\n\r\n    /** Test for the equality of two univariate derivatives.\r\n\r\n     * <p>\r\n\r\n     * univariate derivatives are considered equal if they have the same derivatives.\r\n\r\n     * </p>\r\n\r\n     * @param other Object to test for equality to this\r\n\r\n     * @return true if two univariate derivatives are equal\r\n\r\n     */\r\n\r\n    //override\r\n\r\n    bool equals(Object other) \r\n\r\n    {\r\n\r\n\r\n\r\n        if (this == other) \r\n\r\n        {\r\n\r\n            return true;\r\n\r\n        }\r\n\r\n\r\n\r\n        if (other instanceof Gradient) \r\n\r\n        {\r\n\r\n            const auto rhs = static_cast<Gradient>(other);\r\n\r\n            return my_value == rhs.get_value() && Math_Arrays::equals(my_grad, rhs.grad);\r\n\r\n        }\r\n\r\n\r\n\r\n        return false;\r\n\r\n\r\n\r\n    }\r\n\r\n\r\n\r\n    /** Get a hash_code for the univariate derivative.\r\n\r\n     * @return a hash code value for this object\r\n\r\n     */\r\n\r\n    //override\r\n\r\n    int hash_code() \r\n\r\n    {\r\n\r\n        return 129 + 7 * Double.hash_code(my_value) - 15 * Arrays.hash_code(my_grad);\r\n\r\n    }\r\n\r\n\r\n\r\n};\r\n\r\n